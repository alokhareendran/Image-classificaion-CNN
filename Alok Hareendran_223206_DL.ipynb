{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41cf0727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.15.0-cp39-cp39-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting tensorflow-intel==2.15.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.15.0-cp39-cp39-win_amd64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.4.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached ml_dtypes-0.2.0-cp39-cp39-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.26.2)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (21.3)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached protobuf-4.25.1-cp39-cp39-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.42.0)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached tensorboard-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\new folder (3)\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.41.2)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached grpcio-1.60.0-cp39-cp39-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\new folder (3)\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.33.0)\n",
      "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached google_auth_oauthlib-1.1.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\new folder (3)\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.4)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached protobuf-4.23.4-cp39-cp39-win_amd64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\new folder (3)\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\new folder (3)\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\new folder (3)\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\new folder (3)\\lib\\site-packages (from packaging->tensorflow-intel==2.15.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\new folder (3)\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\new folder (3)\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\new folder (3)\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.7.2)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached google_auth-2.25.1-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\new folder (3)\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\new folder (3)\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\new folder (3)\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\new folder (3)\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\new folder (3)\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached tensorflow-2.15.0-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Using cached tensorflow_intel-2.15.0-cp39-cp39-win_amd64.whl (300.8 MB)\n",
      "Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Using cached ml_dtypes-0.2.0-cp39-cp39-win_amd64.whl (938 kB)\n",
      "Using cached tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "Using cached grpcio-1.60.0-cp39-cp39-win_amd64.whl (3.7 MB)\n",
      "Using cached protobuf-4.23.4-cp39-cp39-win_amd64.whl (422 kB)\n",
      "Using cached google_auth_oauthlib-1.1.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached google_auth-2.25.1-py2.py3-none-any.whl (184 kB)\n",
      "Installing collected packages: protobuf, opt-einsum, oauthlib, ml-dtypes, keras, grpcio, google-pasta, gast, astunparse, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.1\n",
      "    Can't uninstall 'protobuf'. No files were found to uninstall.\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.42.0\n",
      "    Can't uninstall 'grpcio'. No files were found to uninstall.\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 1.33.0\n",
      "    Can't uninstall 'google-auth'. No files were found to uninstall.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    WARNING: No metadata found in d:\\new folder (3)\\lib\\site-packages\n",
      "    WARNING: No metadata found in d:\\new folder (3)\\lib\\site-packages\n",
      "    WARNING: No metadata found in d:\\new folder (3)\\lib\\site-packages\n",
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'D:\\\\New folder (3)\\\\Lib\\\\site-packages\\\\tensorflow\\\\python\\\\_pywrap_tensorflow_internal.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.15.0-cp39-cp39-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting tensorflow-intel==2.15.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.15.0-cp39-cp39-win_amd64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.4.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.6.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached ml_dtypes-0.2.0-cp39-cp39-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.26.2)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (21.3)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached protobuf-4.25.1-cp39-cp39-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.12.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\new folder (3)\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.42.0)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached tensorboard-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\new folder (3)\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.41.2)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached grpcio-1.60.0-cp39-cp39-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\new folder (3)\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.33.0)\n",
      "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached google_auth_oauthlib-1.1.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\new folder (3)\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.4)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached protobuf-4.23.4-cp39-cp39-win_amd64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\new folder (3)\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.27.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\new folder (3)\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\new folder (3)\\lib\\site-packages (from packaging->tensorflow-intel==2.15.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\new folder (3)\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\new folder (3)\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\new folder (3)\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.7.2)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached google_auth-2.25.1-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\new folder (3)\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\new folder (3)\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\new folder (3)\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\new folder (3)\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\new folder (3)\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached tensorflow-2.15.0-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Downloading tensorflow_intel-2.15.0-cp39-cp39-win_amd64.whl (300.8 MB)\n",
      "   -------------------------------------- 300.8/300.8 MB 750.5 kB/s eta 0:00:00\n",
      "Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Using cached libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Downloading ml_dtypes-0.2.0-cp39-cp39-win_amd64.whl (938 kB)\n",
      "   -------------------------------------- 938.4/938.4 kB 873.9 kB/s eta 0:00:00\n",
      "Using cached tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "Downloading grpcio-1.60.0-cp39-cp39-win_amd64.whl (3.7 MB)\n",
      "   ---------------------------------------- 3.7/3.7 MB 819.0 kB/s eta 0:00:00\n",
      "Downloading protobuf-4.23.4-cp39-cp39-win_amd64.whl (422 kB)\n",
      "   -------------------------------------- 422.5/422.5 kB 776.3 kB/s eta 0:00:00\n",
      "Using cached tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached google_auth_oauthlib-1.1.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading google_auth-2.25.1-py2.py3-none-any.whl (184 kB)\n",
      "   -------------------------------------- 184.2/184.2 kB 794.3 kB/s eta 0:00:00\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, protobuf, opt-einsum, oauthlib, ml-dtypes, keras, grpcio, google-pasta, gast, astunparse, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 23.3.3\n",
      "    Uninstalling flatbuffers-23.3.3:\n",
      "      Successfully uninstalled flatbuffers-23.3.3\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.1\n",
      "    Uninstalling protobuf-3.19.1:\n",
      "      Successfully uninstalled protobuf-3.19.1\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.42.0\n",
      "    Uninstalling grpcio-1.42.0:\n",
      "      Successfully uninstalled grpcio-1.42.0\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 1.33.0\n",
      "    Uninstalling google-auth-1.33.0:\n",
      "      Successfully uninstalled google-auth-1.33.0\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.25.1 google-auth-oauthlib-1.1.0 google-pasta-0.2.0 grpcio-1.60.0 keras-2.15.0 libclang-16.0.6 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.4 requests-oauthlib-1.3.1 tensorboard-2.15.1 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-intel-2.15.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-core 1.25.1 requires google-auth<2.0dev,>=1.21.1, but you have google-auth 2.25.1 which is incompatible.\n",
      "google-cloud-core 1.7.1 requires google-auth<2.0dev,>=1.24.0, but you have google-auth 2.25.1 which is incompatible.\n",
      "google-cloud-storage 1.31.0 requires google-auth<2.0dev,>=1.11.0, but you have google-auth 2.25.1 which is incompatible.\n",
      "mediapipe 0.9.3.0 requires protobuf<4,>=3.11, but you have protobuf 4.23.4 which is incompatible.\n",
      "streamlit 1.22.0 requires protobuf<4,>=3.12, but you have protobuf 4.23.4 which is incompatible.\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f64df686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\New folder (3)\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "The length of Virat Kohli images is 41\n",
      "The length of Serena Williams images is 29\n",
      "The length of Maria Sharapova images is 34\n",
      "The length of Rodger Federer images is 28\n",
      "The length of Lionel Messi images is 36\n",
      "--------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Virat Kohli: 41it [00:00, 286.65it/s]\n",
      "Serena Williams: 29it [00:00, 220.52it/s]\n",
      "Roger Federer: 28it [00:00, 230.87it/s]\n",
      "Maria Sharapova: 34it [00:00, 192.05it/s]\n",
      "Lionel Messi: 36it [00:00, 137.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "\n",
      "Dataset Length:  168\n",
      "Label Length:  168\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Train-Test Split\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Normalaising the Dataset. \n",
      "\n",
      "WARNING:tensorflow:From D:\\New folder (3)\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\New folder (3)\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\New folder (3)\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From D:\\New folder (3)\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\New folder (3)\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "3/3 [==============================] - 5s 1s/step - loss: 7.3004 - accuracy: 0.0988 - val_loss: 7.5433 - val_accuracy: 0.2222\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 3s 925ms/step - loss: 8.5236 - accuracy: 0.2346 - val_loss: 3.2371 - val_accuracy: 0.2500\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 2s 786ms/step - loss: 3.7934 - accuracy: 0.1852 - val_loss: 2.4629 - val_accuracy: 0.2500\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 2s 784ms/step - loss: 2.5153 - accuracy: 0.2099 - val_loss: 1.7856 - val_accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 2s 775ms/step - loss: 1.7155 - accuracy: 0.3333 - val_loss: 1.4866 - val_accuracy: 0.3056\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 2s 790ms/step - loss: 1.5173 - accuracy: 0.4198 - val_loss: 1.5213 - val_accuracy: 0.3611\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 2s 797ms/step - loss: 1.4709 - accuracy: 0.3580 - val_loss: 1.5180 - val_accuracy: 0.2222\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 2s 717ms/step - loss: 1.3092 - accuracy: 0.5062 - val_loss: 1.4492 - val_accuracy: 0.3056\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 2s 740ms/step - loss: 1.0678 - accuracy: 0.7160 - val_loss: 1.4290 - val_accuracy: 0.3056\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 2s 735ms/step - loss: 1.0249 - accuracy: 0.6420 - val_loss: 1.1966 - val_accuracy: 0.5833\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 2s 714ms/step - loss: 0.8622 - accuracy: 0.7284 - val_loss: 1.1134 - val_accuracy: 0.6389\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 2s 718ms/step - loss: 0.6866 - accuracy: 0.8519 - val_loss: 1.0554 - val_accuracy: 0.5833\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 2s 718ms/step - loss: 0.5400 - accuracy: 0.8272 - val_loss: 0.9602 - val_accuracy: 0.6389\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 2s 721ms/step - loss: 0.3873 - accuracy: 0.9383 - val_loss: 0.8749 - val_accuracy: 0.6944\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 2s 717ms/step - loss: 0.2828 - accuracy: 0.9383 - val_loss: 0.8039 - val_accuracy: 0.7222\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 2s 717ms/step - loss: 0.2580 - accuracy: 0.9506 - val_loss: 0.8265 - val_accuracy: 0.6667\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 2s 710ms/step - loss: 0.2012 - accuracy: 0.9753 - val_loss: 0.7600 - val_accuracy: 0.7778\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 2s 717ms/step - loss: 0.1927 - accuracy: 0.9506 - val_loss: 0.6874 - val_accuracy: 0.7500\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 2s 710ms/step - loss: 0.1730 - accuracy: 0.9630 - val_loss: 0.7570 - val_accuracy: 0.7500\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 2s 717ms/step - loss: 0.1290 - accuracy: 0.9877 - val_loss: 0.8421 - val_accuracy: 0.7222\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 2s 789ms/step - loss: 0.1016 - accuracy: 0.9753 - val_loss: 0.8710 - val_accuracy: 0.6667\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 2s 755ms/step - loss: 0.1022 - accuracy: 0.9753 - val_loss: 0.6697 - val_accuracy: 0.7500\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 2s 707ms/step - loss: 0.0803 - accuracy: 0.9753 - val_loss: 0.6575 - val_accuracy: 0.7778\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 2s 717ms/step - loss: 0.0657 - accuracy: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.7500\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 2s 709ms/step - loss: 0.0617 - accuracy: 1.0000 - val_loss: 0.6632 - val_accuracy: 0.7500\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 2s 708ms/step - loss: 0.0768 - accuracy: 0.9877 - val_loss: 0.6055 - val_accuracy: 0.8056\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 2s 700ms/step - loss: 0.0556 - accuracy: 0.9877 - val_loss: 0.7415 - val_accuracy: 0.6944\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 2s 702ms/step - loss: 0.0675 - accuracy: 0.9753 - val_loss: 0.9117 - val_accuracy: 0.6944\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 2s 709ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.7792 - val_accuracy: 0.7222\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 2s 711ms/step - loss: 0.0578 - accuracy: 0.9753 - val_loss: 0.8033 - val_accuracy: 0.7500\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 2s 702ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.8855 - val_accuracy: 0.7222\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 2s 709ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.7546 - val_accuracy: 0.8056\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 2s 702ms/step - loss: 0.0411 - accuracy: 0.9877 - val_loss: 0.6916 - val_accuracy: 0.8056\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 2s 701ms/step - loss: 0.0246 - accuracy: 0.9877 - val_loss: 0.6720 - val_accuracy: 0.8056\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 2s 710ms/step - loss: 0.0270 - accuracy: 0.9877 - val_loss: 0.7404 - val_accuracy: 0.7778\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 2s 710ms/step - loss: 0.0408 - accuracy: 0.9753 - val_loss: 0.8623 - val_accuracy: 0.7778\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 2s 710ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.9728 - val_accuracy: 0.7778\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 2s 711ms/step - loss: 0.0380 - accuracy: 0.9753 - val_loss: 0.9556 - val_accuracy: 0.7778\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 2s 718ms/step - loss: 0.0358 - accuracy: 0.9877 - val_loss: 0.9749 - val_accuracy: 0.6944\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 2s 712ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 1.0332 - val_accuracy: 0.7222\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 2s 719ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.0014 - val_accuracy: 0.7222\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 2s 709ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.8384 - val_accuracy: 0.7778\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 2s 709ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.7926 - val_accuracy: 0.8056\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 2s 701ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.8234 - val_accuracy: 0.8056\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 2s 709ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.8527 - val_accuracy: 0.8056\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 2s 709ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.8535 - val_accuracy: 0.8056\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 2s 710ms/step - loss: 0.0220 - accuracy: 0.9877 - val_loss: 0.8944 - val_accuracy: 0.7778\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 2s 701ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.9565 - val_accuracy: 0.7222\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 2s 701ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.9872 - val_accuracy: 0.6944\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 2s 710ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.9586 - val_accuracy: 0.7222\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5843 - accuracy: 0.8431\n",
      "Accuracy: 84.31\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        14\n",
      "           1       0.75      0.67      0.71         9\n",
      "           2       1.00      0.57      0.73         7\n",
      "           3       0.67      0.89      0.76         9\n",
      "           4       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.84        51\n",
      "   macro avg       0.86      0.81      0.82        51\n",
      "weighted avg       0.86      0.84      0.84        51\n",
      "\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "The predicted label for the image is: Lionel Messi\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "image_dir=r\"D:\\assignment\\Dataset_Celebrities\\cropped\"\n",
    "virat_images=os.listdir(image_dir+ '\\\\virat_kohli')\n",
    "serena_images=os.listdir(image_dir+ '\\\\serena_williams')\n",
    "maria_images=os.listdir(image_dir+ '\\\\maria_sharapova')\n",
    "roger_images=os.listdir(image_dir+ '\\\\roger_federer')\n",
    "lionel_images=os.listdir(image_dir+ '\\\\lionel_messi')\n",
    "\n",
    "\n",
    "print(\"--------------------------------------\\n\")\n",
    "\n",
    "print('The length of Virat Kohli images is',len(virat_images))\n",
    "print('The length of Serena Williams images is',len(serena_images))\n",
    "print('The length of Maria Sharapova images is',len(maria_images))\n",
    "print('The length of Rodger Federer images is',len(roger_images))\n",
    "print('The length of Lionel Messi images is',len(lionel_images))\n",
    "\n",
    "\n",
    "\n",
    "print(\"--------------------------------------\\n\")\n",
    "dataset=[]\n",
    "label=[]\n",
    "img_siz=(128,128)\n",
    "\n",
    "\n",
    "for i , image_name in tqdm(enumerate(virat_images),desc=\"Virat Kohli\"):\n",
    "    if(image_name.split('.')[1]=='png'):\n",
    "        image=cv2.imread(image_dir+'/virat_kohli/'+image_name)\n",
    "        image=Image.fromarray(image,'RGB')\n",
    "        image=image.resize(img_siz)\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(0)\n",
    "        \n",
    "        \n",
    "for i ,image_name in tqdm(enumerate(serena_images),desc=\"Serena Williams\"):\n",
    "    if(image_name.split('.')[1]=='png'):\n",
    "        image=cv2.imread(image_dir+'/serena_williams/'+image_name)\n",
    "        image=Image.fromarray(image,'RGB')\n",
    "        image=image.resize(img_siz)\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(1)\n",
    "        \n",
    "for i , image_name in tqdm(enumerate(roger_images),desc=\"Roger Federer\"):\n",
    "    if(image_name.split('.')[1]=='png'):\n",
    "        image=cv2.imread(image_dir+'/roger_federer/'+image_name)\n",
    "        image=Image.fromarray(image,'RGB')\n",
    "        image=image.resize(img_siz)\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(2)\n",
    "        \n",
    "        \n",
    "for i ,image_name in tqdm(enumerate(maria_images),desc=\"Maria Sharapova\"):\n",
    "    if(image_name.split('.')[1]=='png'):\n",
    "        image=cv2.imread(image_dir+'/maria_sharapova/'+image_name)\n",
    "        image=Image.fromarray(image,'RGB')\n",
    "        image=image.resize(img_siz)\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(3)        \n",
    "        \n",
    "for i ,image_name in tqdm(enumerate(lionel_images),desc=\"Lionel Messi\"):\n",
    "    if(image_name.split('.')[1]=='png'):\n",
    "        image=cv2.imread(image_dir+'/lionel_messi/'+image_name)\n",
    "        image=Image.fromarray(image,'RGB')\n",
    "        image=image.resize(img_siz)\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(4)        \n",
    "              \n",
    "dataset=np.array(dataset)\n",
    "label = np.array(label)\n",
    "\n",
    "print(\"--------------------------------------\\n\")\n",
    "print('Dataset Length: ',len(dataset))\n",
    "print('Label Length: ',len(label))\n",
    "print(\"--------------------------------------\\n\")\n",
    "\n",
    "\n",
    "print(\"--------------------------------------\\n\")\n",
    "print(\"Train-Test Split\")\n",
    "x_train,x_test,y_train,y_test=train_test_split(dataset,label,test_size=0.3,random_state=42)\n",
    "print(\"--------------------------------------\\n\")\n",
    "\n",
    "print(\"--------------------------------------\\n\")\n",
    "print(\"Normalaising the Dataset. \\n\")\n",
    "\n",
    "\n",
    "# Normalizing the Dataset\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Correcting the labels if needed (Ensure they range from 0 to 4 for 5 classes)\n",
    "# label = label - 1  # If labels don't start from 0\n",
    "\n",
    "# Build the Model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')  # Change to 5 neurons for 5 classes\n",
    "])\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Change loss function\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the Model\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=32, validation_split=0.3)\n",
    "\n",
    "# Model Evaluation\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Accuracy: {round(accuracy * 100, 2)}')\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Load and preprocess a single image\n",
    "def preprocess_single_image(image_path):\n",
    "    img_size = (128, 128)\n",
    "    image = cv2.imread(image_path)\n",
    "    image = Image.fromarray(image, 'RGB')\n",
    "    image = image.resize(img_size)\n",
    "    image = np.array(image)\n",
    "    image = image.astype('float32') / 255.0\n",
    "    return image\n",
    "\n",
    "# Replace 'path_to_your_image.png' with the path to the image you want to predict\n",
    "image_path_to_predict = r\"D:\\assignment\\Dataset_Celebrities\\cropped\\lionel_messi\\lionel_messi20.png\"\n",
    "\n",
    "# Preprocess the single image\n",
    "single_image = preprocess_single_image(image_path_to_predict)\n",
    "\n",
    "# Reshape the image to fit the model's input shape\n",
    "single_image = np.expand_dims(single_image, axis=0)\n",
    "\n",
    "# Make predictions using the model\n",
    "predictions = model.predict(single_image)\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "class_names = ['Virat Kohli', 'Serena Williams', 'Roger Federer', 'Maria Sharapova', 'Lionel Messi']\n",
    "predicted_label = class_names[predicted_class]\n",
    "\n",
    "print(f\"The predicted label for the image is: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c57db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8b6297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd003790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
