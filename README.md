# Image-classificaion-CNN
The model is a Convolutional Neural Network (CNN) designed for image classification. It comprises several layers, including convolutional layers for feature extraction, max-pooling layers for spatial downsampling, and densely connected layers for classification. The model architecture is sequential, starting with a convolutional layer with 32 filters and ReLU activation. It incorporates dropout layers to mitigate overfitting, and it concludes with an output layer with softmax activation for multi-class classification. The model is compiled using the Adam optimizer and employs sparse categorical cross-entropy as the loss function.

Training Process:
The training process involves feeding the model with the provided dataset, consisting of images of different celebrities. The model learns to associate input images with their corresponding labels during the training epochs. Key training parameters include 50 epochs, a batch size of 32, and a validation split of 30%. The validation split helps monitor the model's performance on unseen data during training, preventing overfitting. The Adam optimizer adjusts the model's weights to minimize the sparse categorical cross-entropy loss, enhancing its ability to generalize to new, unseen images.

Critical Findings:
After training, the model's performance is evaluated on a separate test set. The code prints the accuracy achieved by the model on the test set, providing an overall measure of its effectiveness in correctly classifying images. Additionally, a classification report is generated, offering a more detailed assessment. Precision, recall, and F1-score for each class are provided, shedding light on how well the model performs for individual celebrities. This in-depth analysis is crucial for understanding potential biases or challenges specific to certain classes. The code also demonstrates the model's ability to make predictions on a single image, showcasing its practical application beyond training and evaluation. Further refinement and tuning of hyperparameters could potentially enhance the model's overall performance.
